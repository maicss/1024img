# 1024img

> 闲着没事写的爬虫

主要爬两个页面，分别是[达盖尔的旗帜]和[新时代的我们]。

> 360浏览器有个功能，下载本页面所有图片，而且图片也能设置大小等规则，如果不是大批量的下载，这个够用了。使用我写的这个反而更麻烦，嗯嗯。chrome插件有没有我没找。

## 项目进度

- [ x ] 基本功能完成
- [ x ] 达盖尔的旗帜 测试
- [ ] 新时代的我们 测试
- [ ] 数据库的读写

## 注

不管看不看源码，都应该知道这个爬虫是要经过代理的，具体的代理地址在`settings.js`里面，自己看着配好了


## 数据

返回的数据结构：

```json
{
    "postTitle": "[原创]xxxx[19P]",
    "postDate": " 2017-06-25 17:32 ",
    "url": "http://t66y.com/htm_data/xxx.html",
    "images": [
      "http://passimg.com/images/xxx.jpg",
      "http://passimg.com/images/xxx.jpg",
      "http://passimg.com/images/xxx.jpg"
    ]
  }
```

如果使用文件而非数据库的方式，个人建议是一个论坛页面（也就是90-100个帖子）一个json。具体示例也有，`firstPage.json`。注意数据会包含`null`,这个大部分都是因为网络的原因。这个暂时不想过滤，因为有这个最起码表示帖子去爬了，最起码个数够了，只是没数据而已。

## 其他

主要是想试试node的爬虫，和`async`&`await`的使用。

数据库不是必要的，但是也写了，用的`mongodb`。这个比较有趣，因为官方drive有ES6的教程，使用的是co，也就是generator，现在有了原生的`async`&`await`（其实还是generator）写起来更方便了。

现在（node8）也自带了`promisify`又省了一个库，爽。

大家选择node的原因无非是：

- 会javascript
- 基于事件的异步执行
- 轻量

但是这里主要的目的并不是爬虫，所以异步并发的反而不是优点，所以用了很丑的`setTimeout`控制并发数量~~开着坦克不能压坏路的感觉~~。其实这种场景用python，一个接一个的爬，什么也不用考虑，真的比node爽多了。

图片的下载也写好了，一种是读取本地文件的，另外一种是读取数据库的。

Happy coding~~~

另：我并不是狼友～～